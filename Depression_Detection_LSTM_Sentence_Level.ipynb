{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJLN_Guyi9E8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJyWRMcLCjbB",
        "outputId": "6dd41f8b-ad95-428e-ac19-ebc5e35dc108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pclNO84uR_0",
        "outputId": "564f1f8e-e4ba-4390-d1e0-84ed80520a16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gc\n",
        "import nltk\n",
        "import math\n",
        "from smart_open import open\n",
        "from nltk.corpus import stopwords\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import LSTM, Dense, Bidirectional\n",
        "from keras import layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import concatenate\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzWbjnf8EruV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9968f65-7c3f-4ec5-ad77-5c0ad3a45377"
      },
      "source": [
        "#Text + Audio \n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1, seed=42)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    # Create weight matrices and bias vector. Transform Gate (transforms input feature) and bias.\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "   \n",
        "    #Update gate and bias\n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "   \n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    tensor_t = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    tensor_h = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    #tensor C determines how much of the previous state should be carried over to the new state\n",
        "    tensor_c = tf.subtract(1.0, tensor_t, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(tensor_h, tensor_t), tf.multiply(x, tensor_c), \"y\")\n",
        "\n",
        "class text_audio:\n",
        "  #Define an input layer with 250 timesteps and 74 features\n",
        "  input1 = Input(shape=(250,74), name = 'Audio_input')\n",
        "  highway1 = Highway()(input1)\n",
        "  #Applies another Highway layer to the output of the previous layer (highway1), \n",
        "  #in order to allow network to learn complex nature of the audio input data\n",
        "  highway5 = Highway()(highway1)\n",
        "  #Apply a third Highway layer\n",
        "  highway6 = Highway()(highway5)\n",
        "  #output layer with 74 units, same as number of input features\n",
        "  dense_audio = Dense(74)(highway6)\n",
        "  #print(\"shape of dense_audio \", dense_audio.shape)\n",
        "  input3 = Input(shape = (250,5100), name = 'Text_input')\n",
        "  # Dense layer with 1000 output units to the input layer\n",
        "  dense4 = Dense(1000)(input3)\n",
        "  dense5 = Dense(500)(dense4)\n",
        "  #reduces the number of input features and extracts more important features\n",
        "  dense6 = Dense(250)(dense5)\n",
        "  #final Dense layer with 74 output units\n",
        "  dense_text = Dense(74)(dense6)\n",
        "  #print(\"shape of dense_text \", dense_text.shape)\n",
        "  # merge input models\n",
        "  merge_tensor = concatenate([dense_audio,dense_text], axis = 1)\n",
        "  #128 is number of memory cells in the layer which is a hyperparameter\n",
        "  #20% of the LSTM units will be randomly dropped out during training.\n",
        "  #recurrent_dropout=0.2 (20% of the connections between memory cells in\n",
        "  #the LSTM layer will be randomly dropped out during training)\n",
        "  lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(merge_tensor)\n",
        "  output = Dense(1, activation='sigmoid')(lstm)\n",
        "  model = Model(inputs=[input1, input3], outputs=output)\n",
        "\n",
        "  print(model.summary())\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  def run_model(self):\n",
        "    self.model.compile(optimizer=self.optimizer, loss='binary_crossentropy')\n",
        "\n",
        "    return self.model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Audio_input (InputLayer)       [(None, 250, 74)]    0           []                               \n",
            "                                                                                                  \n",
            " Text_input (InputLayer)        [(None, 250, 5100)]  0           []                               \n",
            "                                                                                                  \n",
            " highway_6 (Highway)            (None, 250, 74)      47952       ['Audio_input[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 250, 1000)    5101000     ['Text_input[0][0]']             \n",
            "                                                                                                  \n",
            " highway_7 (Highway)            (None, 250, 74)      47952       ['highway_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 250, 500)     500500      ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " highway_8 (Highway)            (None, 250, 74)      47952       ['highway_7[0][0]']              \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 250, 250)     125250      ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 250, 74)      5550        ['highway_8[0][0]']              \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 250, 74)      18574       ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 500, 74)      0           ['dense_12[0][0]',               \n",
            "                                                                  'dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 128)          103936      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 1)            129         ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,998,795\n",
            "Trainable params: 5,998,795\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHCKLXfLx3Kc"
      },
      "source": [
        "dev_location = \"dev_data\"\n",
        "test_location = \"test_data\"\n",
        "train_location = \"train_data\"\n",
        "\n",
        "devData = np.array(pd.read_csv('/content/drive/MyDrive/diacwoz/dev_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "testData = np.array(pd.read_csv('/content/drive/MyDrive/diacwoz/full_test_split.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "trainData = np.array(pd.read_csv('/content/drive/MyDrive/diacwoz/train_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "\n",
        "dataset = np.concatenate((devData, np.concatenate((testData, trainData))))   \n",
        "max_num_words = 17\n",
        "pretrained_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def getData(patientID, data_loc):\n",
        "  retData = [int(patientID)]\n",
        "  text_data = getTextData(patientID, data_loc)\n",
        "  audio_data = audioData(patientID, data_loc, text_data)\n",
        "  return text_data, audio_data\n",
        "\n",
        "def getTextData(patientID, data_loc):\n",
        "  fileName = \"/content/drive/MyDrive/diacwoz/\"+ str(data_loc) + \"/\" + str(int(patientID)) + \"_TRANSCRIPT.csv\"\n",
        "  #print(\"filename is \", fileName)\n",
        "  arr_file = np.array(pd.read_csv(fileName, delimiter='\\t',encoding='utf-8', engine='python'))\n",
        "\n",
        "  for i in range(len(arr_file)):\n",
        "    if(arr_file[i][2] != 'Participant'):\n",
        "      np.delete(arr_file, i)\n",
        "      i-=1\n",
        "\n",
        "  # Remove Speaker Columnn\n",
        "  arr_file = np.delete(arr_file, 2, 1)\n",
        "  \n",
        "  # Convert text into word vectors. 300 is dimension of\n",
        "  # the word vectors being used\n",
        "  word_vecs = np.zeros((1, max_num_words*300))\n",
        "  for i in range(len(arr_file)):\n",
        "    sentence = arr_file[i][2]\n",
        "    word_vec = wordToVec(sentence)\n",
        "    word_vecs = np.concatenate((word_vecs, word_vec), axis = 0)\n",
        "  word_vecs = np.delete(word_vecs, 0, 0)  \n",
        "\n",
        "  # Delete Sentences and Replace With W2Vs\n",
        "  arr_file = np.delete(arr_file, 2, 1)\n",
        "  arr_file = np.concatenate((arr_file, word_vecs), axis = 1)\n",
        "  return arr_file\n",
        "\n",
        "def dataExistence(patientID, data_type):\n",
        "  for id in data_type:\n",
        "    if(patientID == id[0]):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "#Remove stopwords (and, is, of etc.) which reduces text data dimensionality\n",
        "def remove_StopWords(sentence):\n",
        "    filtered_sentence = [] \n",
        "    for w in sentence: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)\n",
        "    return filtered_sentence\n",
        "\n",
        "def wordToVec(sentence):\n",
        "  global max_num_words, stop_words, pretrained_model\n",
        "  sentence = str(sentence).split(\" \")\n",
        "  sentence = remove_StopWords(sentence)\n",
        "  index_word = 0\n",
        "  wordMatrix = np.zeros(max_num_words*300)\n",
        "  for j in range(min(max_num_words, len(sentence))):\n",
        "    try:\n",
        "      word = sentence[j]\n",
        "      if(word[0] == '<'):\n",
        "        if(word.find('>')!=-1):\n",
        "          word = word[1:-1]\n",
        "        else:\n",
        "          word = word[1:]\n",
        "      else:\n",
        "        if(word.find('>')!=-1):\n",
        "          word = word[0:-1]\n",
        "      ss = np.array(pretrained_model[word])\n",
        "      wordMatrix[index_word*300:(index_word+1)*300] = ss\n",
        "      index_word+=1\n",
        "    except Exception as e:\n",
        "      continue\n",
        "  wordMatrix = np.array(wordMatrix.reshape(1,-1))\n",
        "  return wordMatrix\n",
        "\n",
        "def audioDataHelper(X):\n",
        "    for i in range(X.shape[0]):\n",
        "        if(X[i,1] == 0):\n",
        "            X[i,0] = 0\n",
        "            for j in range(7):\n",
        "                X[i,j+1] = 0\n",
        "    X = np.array(X)\n",
        "    return X\n",
        "    \n",
        "def audioData(patientID, location, textD):\n",
        "  fileName = \"/content/drive/MyDrive/diacwoz/\"+ str(location) + \"/\" + str(int(patientID)) + \"_COVAREP.csv\"\n",
        "  data = pd.read_csv(fileName,header = None)\n",
        "  data = data.iloc[:,:].values\n",
        "  data = audioDataHelper(data)\n",
        "  # print(\"Audio Raw Data:\" + str(data.shape))\n",
        "  sentenceDatas = []\n",
        "  for sentence in textD:\n",
        "    sentenceStartime = sentence[0]\n",
        "    sentenceEndTime = sentence[1]\n",
        "    startIndex = math.floor(sentenceStartime/0.01)\n",
        "    endIndex = math.ceil(sentenceEndTime/0.01)\n",
        "    sentenceData = data[startIndex: endIndex]\n",
        "    sentenceData = np.average(sentenceData, axis = 0)\n",
        "    #reshape to 1D Array with one row and variable number of columns\n",
        "    sentenceData = np.array(sentenceData.reshape(1, -1))\n",
        "    sentenceDatas.append(sentenceData)\n",
        "  \n",
        "  sentenceDatas = np.array(sentenceDatas)\n",
        "  sentenceDatas = np.reshape(sentenceDatas, (textD.shape[0],-1))\n",
        "  return sentenceDatas\n",
        "\n",
        "y_train = []\n",
        "y_test = []\n",
        "audio_train = []\n",
        "text_train = []\n",
        "audio_test = []\n",
        "text_test = []\n",
        "\n",
        "for datapoint in dataset:\n",
        "  if(dataExistence(datapoint[0], devData)):\n",
        "    text,audio = getData(datapoint[0], dev_location)\n",
        "    audio_train.append(audio)\n",
        "    text_train.append(text)\n",
        "    y_train.append(datapoint[1])\n",
        "  elif(dataExistence(datapoint[0], testData)):\n",
        "    # Data Point in Test Set\n",
        "    text,audio = getData(datapoint[0], test_location)\n",
        "    audio_test.append(audio)\n",
        "    text_test.append(text)\n",
        "    y_test.append(datapoint[1])\n",
        "  elif(dataExistence(datapoint[0], trainData)):\n",
        "    text,audio = getData(datapoint[0], train_location)\n",
        "    audio_train.append(audio)\n",
        "    text_train.append(text)\n",
        "    y_train.append(datapoint[1])\n",
        "\n",
        "def refactor(arr, size):\n",
        "  arrsize = arr.shape[0]\n",
        "  temp = np.zeros((size, arr.shape[1]))\n",
        "  for i in range(min(len(arr), size)):\n",
        "    temp[i] = arr[i]\n",
        "  return temp\n",
        "\n",
        "numberOfSentences = 250\n",
        "\n",
        "devData = []\n",
        "trainData = []\n",
        "testData = []\n",
        "gc.collect()\n",
        "\n",
        "for i in range(len(audio_train)):\n",
        "  audio_train[i] = refactor(audio_train[i], numberOfSentences)\n",
        "  text_train[i] = refactor(text_train[i], numberOfSentences)\n",
        "\n",
        "for i in range(len(audio_test)):\n",
        "  audio_test[i] = refactor(audio_train[i], numberOfSentences)\n",
        "  text_test[i] = refactor(text_train[i], numberOfSentences)\n",
        "\n",
        "audio_test = np.array(audio_test)\n",
        "text_test = np.array(text_test)\n",
        "text_test = text_test[:,:,2:]\n",
        "\n",
        "audio_train = np.array(audio_train)\n",
        "text_train = np.array(text_train)\n",
        "text_train = text_train[:,:,2:]\n",
        "\n",
        "dataset = []\n",
        "gc.collect()\n",
        "\n",
        "print(audio_train.shape,text_train.shape)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "audio_train = np.nan_to_num(audio_train)\n",
        "text_train = np.nan_to_num(text_train)\n",
        "#print(audio_train.shape)\n",
        "#print(text_train.shape)\n",
        "#print(y_train.shape)\n",
        "\n",
        "for i in range(audio_train.shape[0]):\n",
        "  #normalize to avoid features with large values dominate\n",
        "  audio_train[i] = sklearn.preprocessing.normalize(audio_train[i])\n",
        "  text_train[i] = sklearn.preprocessing.normalize(text_train[i])\n",
        "\n",
        "audio_test = np.nan_to_num(audio_test)\n",
        "text_test = np.nan_to_num(text_test)\n",
        "\n",
        "for i in range(audio_test.shape[0]):\n",
        "  audio_test[i] = sklearn.preprocessing.normalize(audio_test[i])\n",
        "  text_test[i] = sklearn.preprocessing.normalize(text_test[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbT2jzhhu4Om",
        "outputId": "ad5fe2e1-93a5-4c3f-e9e5-95a9eaef7955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"With Gating sentence level\")\n",
        "text_audio_model = text_audio()\n",
        "result_model = text_audio_model.run_model()\n",
        "\n",
        "result_model.fit([audio_train,text_train], y_train, validation_split = 0.2, epochs=25, batch_size = 125)\n",
        "\n",
        "pred = result_model.predict([audio_test,text_test])\n",
        "pred2 = result_model.predict([audio_train,text_train])\n",
        "#print(\"test prediction \" ,pred)\n",
        "#print(\"\\ntrain prediction \", pred2)\n",
        "y_pred_train = (pred2 >= 0.5).astype(int)\n",
        "y_pred = (pred >= 0.5).astype(int)\n",
        "print(\"Training score: \", classification_report(y_train, y_pred_train))\n",
        "print(\"Validation score: \", classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With Gating sentence level\n",
            "Epoch 1/25\n",
            "1/1 [==============================] - 14s 14s/step - loss: 0.5742 - val_loss: 0.5078\n",
            "Epoch 2/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.5620 - val_loss: 0.4990\n",
            "Epoch 3/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5553 - val_loss: 0.4887\n",
            "Epoch 4/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.5460 - val_loss: 0.4765\n",
            "Epoch 5/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.5375 - val_loss: 0.4623\n",
            "Epoch 6/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5287 - val_loss: 0.4462\n",
            "Epoch 7/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.5192 - val_loss: 0.4291\n",
            "Epoch 8/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.5130 - val_loss: 0.4127\n",
            "Epoch 9/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.5040 - val_loss: 0.3982\n",
            "Epoch 10/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4978 - val_loss: 0.3869\n",
            "Epoch 11/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4874 - val_loss: 0.3786\n",
            "Epoch 12/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.4809 - val_loss: 0.3733\n",
            "Epoch 13/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4735 - val_loss: 0.3710\n",
            "Epoch 14/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.4633 - val_loss: 0.3711\n",
            "Epoch 15/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4535 - val_loss: 0.3733\n",
            "Epoch 16/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4462 - val_loss: 0.3769\n",
            "Epoch 17/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4366 - val_loss: 0.3818\n",
            "Epoch 18/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4283 - val_loss: 0.3875\n",
            "Epoch 19/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4217 - val_loss: 0.3942\n",
            "Epoch 20/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4159 - val_loss: 0.4020\n",
            "Epoch 21/25\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.4056 - val_loss: 0.4107\n",
            "Epoch 22/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4011 - val_loss: 0.4203\n",
            "Epoch 23/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3939 - val_loss: 0.4303\n",
            "Epoch 24/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3894 - val_loss: 0.4406\n",
            "Epoch 25/25\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3841 - val_loss: 0.4506\n",
            "2/2 [==============================] - 2s 560ms/step\n",
            "5/5 [==============================] - 4s 675ms/step\n",
            "Training score:                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.99      0.90       100\n",
            "         1.0       0.95      0.48      0.63        42\n",
            "\n",
            "    accuracy                           0.84       142\n",
            "   macro avg       0.89      0.73      0.77       142\n",
            "weighted avg       0.86      0.84      0.82       142\n",
            "\n",
            "Validation score:                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.82      0.78        33\n",
            "         1.0       0.45      0.36      0.40        14\n",
            "\n",
            "    accuracy                           0.68        47\n",
            "   macro avg       0.60      0.59      0.59        47\n",
            "weighted avg       0.66      0.68      0.67        47\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Icl7Va_k_dwT"
      }
    }
  ]
}