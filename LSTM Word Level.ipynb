{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PcTb_29wKVOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "im-jXWnEJSx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0487ec59-31f8-4cf2-fbe0-9ff98b9eb05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import gc\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from smart_open import open\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "dev_location = \"dev_data\"\n",
        "test_location = \"test_data\"\n",
        "train_location = \"train_data\"\n",
        "\n",
        "devData = np.array(pd.read_csv('/content/drive/My Drive/diacwoz/dev_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "testData = np.array(pd.read_csv('/content/drive/My Drive/diacwoz/full_test_split.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "trainData = np.array(pd.read_csv('/content/drive/My Drive/diacwoz/train_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
        "\n",
        "dataset = np.concatenate((devData, np.concatenate((testData, trainData))))\n",
        "\n",
        "gc.collect()      \n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def patient_id_check(patientID, split):\n",
        "  for i in split:\n",
        "    if(patientID == i[0]):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def load_text(patientID, location):\n",
        "  #print(\"PatientID: \" + str(int(patientID)))\n",
        "  p_id = [int(patientID)]\n",
        "  text_Dim = load_text_data(patientID, location)\n",
        "  text_Dim = np.array(text_Dim)\n",
        "\n",
        "  return text_Dim\n",
        "\n",
        "def load_text_data(patientID, location):\n",
        "  fileName = \"/content/drive/My Drive/diacwoz/\"+ str(location) + \"/\" + str(int(patientID)) + \"_TRANSCRIPT.csv\"\n",
        "  file = np.array(pd.read_csv(fileName,delimiter='\\t',encoding='utf-8', engine='python'))\n",
        "  outputList = []\n",
        "\n",
        "  for i in range(len(file)):\n",
        "    line = file[i][3]\n",
        "    words = str(line).split(\" \")\n",
        "    char_count_tot = 0\n",
        "    for word in words: \n",
        "      char_count_tot += len(word)\n",
        "\n",
        "    line_s = file[i][0] \n",
        "    line_e = file[i][1]\n",
        "    speaker = file[i][2]\n",
        "    if speaker == 'Ellie':\n",
        "      continue\n",
        "    else:\n",
        "      speaker = 1\n",
        "\n",
        "    totalTime = line_e - line_s\n",
        "    sec_cha = totalTime/char_count_tot\n",
        "\n",
        "    w_s = line_s\n",
        "    for word in words:\n",
        "      w_e = w_s + (sec_cha * len(word))\n",
        "      appender = [w_s, w_e, speaker]\n",
        "      vector = list(vec(word))\n",
        "      for v in vector:\n",
        "        appender.append(v)\n",
        "      outputList.append(appender)\n",
        "      w_s = w_e\n",
        "\n",
        "  return outputList\n",
        "\n",
        "def remove_StopWords(line):\n",
        "    filtered_sentence = [] \n",
        "    for w in line: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)\n",
        "    return filtered_sentence\n",
        "\n",
        "def vec(word):\n",
        "  word = str(word)\n",
        "  try:\n",
        "    if word[0] == '<':\n",
        "        word = word[1:]\n",
        "    if word[-1] == '>':\n",
        "        word = word[0:-1]\n",
        "  except:\n",
        "    gab = 3\n",
        "  if(word in model):\n",
        "      return np.array(model[word])\n",
        "  else:\n",
        "    return np.zeros((300))\n",
        "\n",
        "\n",
        "Ytrain = []\n",
        "Ytest = []\n",
        "text_train = []\n",
        "text_test = []\n",
        "\n",
        "\n",
        "lengths = []\n",
        "for datapoint in dataset:\n",
        "  if(patient_id_check(datapoint[0], devData)):\n",
        "\n",
        "    datapoint in devData\n",
        "    text = load_text(datapoint[0], dev_location)\n",
        "    text = text[:,2:]\n",
        "    text_train.append(text)\n",
        "    Ytrain.append(datapoint[1])\n",
        "  if(patient_id_check(datapoint[0], testData)):\n",
        "    text = load_text(datapoint[0], test_location)\n",
        "    text = text[:,2:]\n",
        "    text_test.append(text)\n",
        "    Ytest.append(datapoint[1])\n",
        "  elif(patient_id_check(datapoint[0], trainData)):\n",
        "    text = load_text(datapoint[0], train_location)\n",
        "    text = text[:,2:]\n",
        "    text_train.append(text)\n",
        "    Ytrain.append(datapoint[1])\n",
        "model = []\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "def vec_length_corr(arr, size):\n",
        "  temp = arr[0:min(len(arr),size), :]\n",
        "  if (len(temp) < size):\n",
        "    temp = np.concatenate((temp, np.zeros(((size - len(temp)), arr.shape[1]))), axis = 0 )\n",
        "  return temp\n",
        "\n",
        "tot_lines = 1700\n",
        "\n",
        "for i in range(len(text_train)):\n",
        "  text_train[i] = vec_length_corr(text_train[i], tot_lines)\n",
        "\n",
        "for i in range(len(text_test)):\n",
        "  text_test[i] = vec_length_corr(text_train[i], tot_lines)\n",
        "\n",
        "text_test = np.array(text_test)\n",
        "\n",
        "text_train = np.array(text_train)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(text_test.shape)\n",
        "print(text_train.shape)\n",
        "\n",
        "dataset = []\n",
        "devData = []\n",
        "trainData = []\n",
        "testdata = []\n",
        "gc.collect()\n",
        "\n",
        "Ytrain = np.array(Ytrain)\n",
        "Ytest = np.array(Ytest)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def upsample(X_train,Y_train):\n",
        "  X_train_0 = X_train[Y_train==0]\n",
        "  X_train_1 = X_train[Y_train==1]\n",
        "\n",
        "  Y_train_1 = Y_train[Y_train==1]\n",
        "  size = X_train_0.shape[0] - X_train_1.shape[0]\n",
        "  X = []\n",
        "  Y = []\n",
        "  X_train = list(X_train)\n",
        "  Y_train = list(Y_train)\n",
        "  while(size>0):\n",
        "    size -= 1\n",
        "    index = np.random.randint(0,X_train_1.shape[0]-1)\n",
        "    leave_index = np.random.randint(0,len(X_train)-1)\n",
        "    X_add = X_train_1[index]\n",
        "    X_leave = X_train[leave_index]\n",
        "\n",
        "    Y_add = Y_train_1[index]\n",
        "    Y_leave = Y_train[leave_index]\n",
        "\n",
        "    X_train[leave_index] = X_add\n",
        "    X_train.append(X_leave)\n",
        "\n",
        "    Y_train[leave_index] = Y_add\n",
        "    Y_train.append(Y_leave)\n",
        "\n",
        "\n",
        "  X_train = np.array(X_train)\n",
        "  Y_train = np.array(Y_train)\n",
        "  return X_train,Y_train\n",
        "\n",
        "\n",
        "text_train = np.nan_to_num(text_train)\n",
        "\n",
        "\n",
        "text_train, Ytrain = upsample(text_train,Ytrain)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "for i in range(text_train.shape[0]):\n",
        "  text_train[i] = sklearn.preprocessing.normalize(text_train[i])\n",
        "\n",
        "\n",
        "text_test = np.nan_to_num(text_test)\n",
        "\n",
        "\n",
        "for i in range(text_test.shape[0]):\n",
        "  text_test[i] = sklearn.preprocessing.normalize(text_test[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_cwcZnFKYar",
        "outputId": "19e7b75d-0fb4-4864-d920-265b351c2994"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47, 1700, 301)\n",
            "(142, 1700, 301)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Highway(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Highway, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    n_sentences = input_shape[1]\n",
        "    n_features = input_shape[2]\n",
        "    carry_bias = keras.initializers.Constant(value=-1.0)\n",
        "    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
        "\n",
        "    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n",
        "\n",
        "    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n",
        "    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n",
        "   \n",
        "    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n",
        "    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n",
        "    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n",
        "    C = tf.subtract(1.0, T, name=\"carry_gate\")\n",
        "    \n",
        "    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n",
        "\n",
        "\n",
        "# Multiple Inputs\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "\n",
        "input3 = Input(shape = (1700,301), name = 'Text_input')\n",
        "\n",
        "highway2 = Highway()(input3)\n",
        "highway3 = Highway()(highway2)\n",
        "dense6 = Dense(903)(highway3)\n",
        "dense3 = Dense(452)(dense6)\n",
        "dense2 = Dense(55)(dense3)\n",
        "# merge input models dense 2 output is connected to input\n",
        "merge = concatenate([dense2], axis = 1)\n",
        "# interpretation model\n",
        "lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(merge)\n",
        "output = Dense(1, activation='sigmoid')(lstm)\n",
        "model = Model(inputs=[ input3], outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "\n",
        "model.fit([text_train],Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='min',\n",
        "    baseline=None, restore_best_weights=True),epochs=50, batch_size = 2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Thresholding(Y_pred, threshold):\n",
        "  Y_pred2 = []\n",
        "  print(\"Y_pred: \", Y_pred.shape)\n",
        "  for i in range(len(Y_pred)):\n",
        "    if(Y_pred[i] < threshold):\n",
        "      Y_pred2.append(0)\n",
        "    else:\n",
        "      Y_pred2.append(1)\n",
        "\n",
        "  return np.array(Y_pred2)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict([text_test])\n",
        "pred2 = model.predict([text_train])\n",
        "\n",
        "\n",
        "print(classification_report(Ytest,Thresholding(pred,0.5)))\n",
        "print(\"TRAINING ACCCCCC        \" , classification_report(Ytrain,Thresholding(pred2,0.5)))\n",
        "\n",
        "print(classification_report(Ytest,Thresholding(pred,0.6)))\n",
        "\n",
        "print(classification_report(Ytest,Thresholding(pred,0.4)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.3)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.7)))\n",
        "print(classification_report(Ytest,Thresholding(pred,0.8)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_SV8i50KcSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0654ca79-9e2b-47b3-bf17-7ebbe63fa1f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Text_input (InputLayer)     [(None, 1700, 301)]       0         \n",
            "                                                                 \n",
            " highway_4 (Highway)         (None, 1700, 301)         1204602   \n",
            "                                                                 \n",
            " highway_5 (Highway)         (None, 1700, 301)         1204602   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1700, 903)         272706    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1700, 452)         408608    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1700, 55)          24915     \n",
            "                                                                 \n",
            " concatenate_2 (Concatenate)  (None, 1700, 55)         0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               94208     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,209,770\n",
            "Trainable params: 3,209,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "80/80 [==============================] - 344s 4s/step - loss: 0.7007 - val_loss: 0.6951\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 342s 4s/step - loss: 0.6896 - val_loss: 0.6975\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 324s 4s/step - loss: 0.6908 - val_loss: 0.6958\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 335s 4s/step - loss: 0.6769 - val_loss: 0.7013\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 335s 4s/step - loss: 0.6664 - val_loss: 0.7101\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 325s 4s/step - loss: 0.6420 - val_loss: 0.7071\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 322s 4s/step - loss: 0.6360 - val_loss: 0.7011\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 319s 4s/step - loss: 0.6154 - val_loss: 0.6919\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 324s 4s/step - loss: 0.5794 - val_loss: 0.6942\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 334s 4s/step - loss: 0.5379 - val_loss: 0.6697\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 345s 4s/step - loss: 0.4998 - val_loss: 0.6513\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 325s 4s/step - loss: 0.4918 - val_loss: 0.6966\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 317s 4s/step - loss: 0.4858 - val_loss: 0.6826\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 320s 4s/step - loss: 0.4467 - val_loss: 0.6936\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 318s 4s/step - loss: 0.4376 - val_loss: 0.7046\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 328s 4s/step - loss: 0.4390 - val_loss: 0.7081\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 327s 4s/step - loss: 0.4442 - val_loss: 0.7150\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 314s 4s/step - loss: 0.4376 - val_loss: 0.7155\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 314s 4s/step - loss: 0.4404 - val_loss: 0.6998\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 312s 4s/step - loss: 0.4383 - val_loss: 0.6903\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 322s 4s/step - loss: 0.4359 - val_loss: 0.6672\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 313s 4s/step - loss: 0.4331 - val_loss: 0.6880\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 315s 4s/step - loss: 0.4350 - val_loss: 0.6818\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 318s 4s/step - loss: 0.4374 - val_loss: 0.6955\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 322s 4s/step - loss: 0.4337 - val_loss: 0.6581\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 318s 4s/step - loss: 0.4341 - val_loss: 0.6385\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 324s 4s/step - loss: 0.4333 - val_loss: 0.6683\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 319s 4s/step - loss: 0.4312 - val_loss: 0.6332\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 324s 4s/step - loss: 0.4359 - val_loss: 0.6869\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 314s 4s/step - loss: 0.4327 - val_loss: 0.6769\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 310s 4s/step - loss: 0.4341 - val_loss: 0.6717\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 307s 4s/step - loss: 0.4323 - val_loss: 0.6720\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 306s 4s/step - loss: 0.4331 - val_loss: 0.6087\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 308s 4s/step - loss: 0.4333 - val_loss: 0.6733\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 308s 4s/step - loss: 0.4466 - val_loss: 0.7578\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 307s 4s/step - loss: 0.4361 - val_loss: 0.6546\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 308s 4s/step - loss: 0.4324 - val_loss: 0.6450\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 303s 4s/step - loss: 0.4343 - val_loss: 0.6237\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 311s 4s/step - loss: 0.4334 - val_loss: 0.6578\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 309s 4s/step - loss: 0.4312 - val_loss: 0.7141\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 310s 4s/step - loss: 0.4360 - val_loss: 0.6482\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 309s 4s/step - loss: 0.4307 - val_loss: 0.6116\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 306s 4s/step - loss: 0.4320 - val_loss: 0.6294\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 305s 4s/step - loss: 0.4317 - val_loss: 0.6570\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 300s 4s/step - loss: 0.4367 - val_loss: 0.6788\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 293s 4s/step - loss: 0.4359 - val_loss: 0.6239\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 295s 4s/step - loss: 0.4312 - val_loss: 0.6724\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 299s 4s/step - loss: 0.4311 - val_loss: 0.6694\n",
            "2/2 [==============================] - 5s 1s/step\n",
            "7/7 [==============================] - 21s 3s/step\n",
            "Y_pred:  (47, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.88      0.81        33\n",
            "         1.0       0.50      0.29      0.36        14\n",
            "\n",
            "    accuracy                           0.70        47\n",
            "   macro avg       0.62      0.58      0.58        47\n",
            "weighted avg       0.67      0.70      0.67        47\n",
            "\n",
            "Y_pred:  (200, 1)\n",
            "TRAINING ACCCCCC                       precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.99      0.76       100\n",
            "         1.0       0.98      0.40      0.57       100\n",
            "\n",
            "    accuracy                           0.69       200\n",
            "   macro avg       0.80      0.70      0.67       200\n",
            "weighted avg       0.80      0.69      0.67       200\n",
            "\n",
            "Y_pred:  (47, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.88      0.81        33\n",
            "         1.0       0.50      0.29      0.36        14\n",
            "\n",
            "    accuracy                           0.70        47\n",
            "   macro avg       0.62      0.58      0.58        47\n",
            "weighted avg       0.67      0.70      0.67        47\n",
            "\n",
            "Y_pred:  (47, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.21        33\n",
            "         1.0       0.29      0.86      0.44        14\n",
            "\n",
            "    accuracy                           0.34        47\n",
            "   macro avg       0.48      0.49      0.32        47\n",
            "weighted avg       0.56      0.34      0.27        47\n",
            "\n",
            "Y_pred:  (47, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.21        33\n",
            "         1.0       0.29      0.86      0.44        14\n",
            "\n",
            "    accuracy                           0.34        47\n",
            "   macro avg       0.48      0.49      0.32        47\n",
            "weighted avg       0.56      0.34      0.27        47\n",
            "\n",
            "Y_pred:  (47, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.91      0.82        33\n",
            "         1.0       0.57      0.29      0.38        14\n",
            "\n",
            "    accuracy                           0.72        47\n",
            "   macro avg       0.66      0.60      0.60        47\n",
            "weighted avg       0.70      0.72      0.69        47\n",
            "\n",
            "Y_pred:  (47, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.91      0.82        33\n",
            "         1.0       0.57      0.29      0.38        14\n",
            "\n",
            "    accuracy                           0.72        47\n",
            "   macro avg       0.66      0.60      0.60        47\n",
            "weighted avg       0.70      0.72      0.69        47\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(Ytest,Thresholding(pred,0.95)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ91rUq-k0qK",
        "outputId": "8283921d-9c4f-4d83-b003-3f52bbfc35c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred:  (47, 1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.91      0.82        33\n",
            "         1.0       0.57      0.29      0.38        14\n",
            "\n",
            "    accuracy                           0.72        47\n",
            "   macro avg       0.66      0.60      0.60        47\n",
            "weighted avg       0.70      0.72      0.69        47\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = [[9.0,9.0]]\n",
        "x1 = np.zeros(len(Ytest))\n",
        "x2 = np.zeros(len(Ytest))\n",
        "y1 = np.zeros(len(Ytest))\n",
        "y2 = np.zeros(len(Ytest))\n",
        "for i in range(len(Ytest)):\n",
        "  i_lo = [[Ytest[i],pred[i][0]]]\n",
        "  x1[i] = i+1\n",
        "  x2[i] = i+1\n",
        "  if Ytest[i] == 0:\n",
        "    y1[i] = pred[i][0]\n",
        "  else:\n",
        "    y2[i] = pred[i][0]\n",
        "  test_pred = np.append(test_pred,i_lo,axis=0)\n",
        "\n",
        "test_pred = np.delete(test_pred, 0, 0)\n",
        "print(test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss93JbkYrBJ-",
        "outputId": "7ed032c0-8627-47f4-8f00-fc88a04162c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.39657122]\n",
            " [0.         0.01826781]\n",
            " [0.         0.39657131]\n",
            " [1.         0.39657122]\n",
            " [1.         0.98938483]\n",
            " [1.         0.99864918]\n",
            " [0.         0.99915409]\n",
            " [0.         0.40109462]\n",
            " [0.         0.39657122]\n",
            " [1.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [1.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [1.         0.39657122]\n",
            " [1.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [1.         0.98969084]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39637893]\n",
            " [1.         0.39657122]\n",
            " [0.         0.99351573]\n",
            " [0.         0.39657122]\n",
            " [0.         0.75035816]\n",
            " [1.         0.99132949]\n",
            " [0.         0.02811581]\n",
            " [0.         0.39657122]\n",
            " [1.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [1.         0.01211242]\n",
            " [0.         0.01008352]\n",
            " [0.         0.98548746]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.02250539]\n",
            " [0.         0.39657122]\n",
            " [1.         0.04139025]\n",
            " [1.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]\n",
            " [0.         0.39657122]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x1, y1, c =\"pink\",\n",
        "            linewidths = 2,\n",
        "            marker =\"s\",\n",
        "            edgecolor =\"green\",\n",
        "            s = 50)\n",
        " \n",
        "plt.scatter(x2, y2, c =\"yellow\",\n",
        "            linewidths = 2,\n",
        "            marker =\"^\",\n",
        "            edgecolor =\"red\",\n",
        "            s = 200)\n",
        " \n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "vBNhX--DrF_T",
        "outputId": "575aae89-7f2a-47cb-c408-812f95ee52df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "newData = pd.read_excel('/content/drive/MyDrive/AI ML/logisctic.xlsx')\n",
        "\n",
        "x = newData.iloc[:, [3]].values\n",
        "y = newData.iloc[:, 1].values\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2OFdK5xrMxl",
        "outputId": "6cb3e999-2de0-4db8-819e-0df4d4f39fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.45002955]\n",
            " [0.46505043]\n",
            " [0.45002952]\n",
            " [0.45002952]\n",
            " [0.60440147]\n",
            " [0.47515643]\n",
            " [0.41103938]\n",
            " [0.45003659]\n",
            " [0.45002952]\n",
            " [0.45002955]\n",
            " [0.45002952]\n",
            " [0.45002952]\n",
            " [0.45002955]\n",
            " [0.45002955]\n",
            " [0.45002955]\n",
            " [0.45002955]\n",
            " [0.51328653]\n",
            " [0.45002952]\n",
            " [0.45002002]\n",
            " [0.45002955]\n",
            " [0.43602717]\n",
            " [0.45002955]\n",
            " [0.46004692]\n",
            " [0.70302463]\n",
            " [0.52240366]\n",
            " [0.45002952]\n",
            " [0.45002952]\n",
            " [0.45002955]\n",
            " [0.38980383]\n",
            " [0.39151099]\n",
            " [0.4381611 ]\n",
            " [0.45002955]\n",
            " [0.45002952]\n",
            " [0.45002952]\n",
            " [0.45002952]\n",
            " [0.37414137]\n",
            " [0.45002952]\n",
            " [0.37380275]\n",
            " [0.45002952]\n",
            " [0.45002955]\n",
            " [0.45002952]\n",
            " [0.45002955]]\n",
            "[0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "xtrain, xtest, ytrain, ytest = train_test_split(\n",
        "    x, y, test_size=0.4, random_state=42)\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(xtrain, ytrain)\n",
        "\n",
        "y_pred = classifier.predict(xtest)\n",
        "print(ytrain, ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PVFNijNrV-K",
        "outputId": "1ad685bc-99f5-4345-c981-56a95c704f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1] [0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "  \n",
        "cm = confusion_matrix(ytest, y_pred)\n",
        "print (\"Confusion Matrix : \\n\", cm)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "print (\"Accuracy : \", accuracy_score(ytest, y_pred))\n",
        "print (\"F1 : \", f1_score(ytest, y_pred))\n",
        "\n",
        "print(ytest, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co5GmjKnrY52",
        "outputId": "9848af6c-dff3-49b2-ffb9-930980072491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            " [[11  0]\n",
            " [ 6  0]]\n",
            "Accuracy :  0.6470588235294118\n",
            "F1 :  0.0\n",
            "[0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    }
  ]
}